---
title: "SDS 322E: Project 1 Report"
output: html_document
---

## Names and EIDs of Group Members
Jonathan Choi, jhc3264
Dana Lee, ddl2249
Joseph Choi, 

## Load the Data

```{r setup, include=FALSE}
## Do not modify this code chunk
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
```



```{r, cache=FALSE, message=FALSE}
## This chunk may take a long time to run. Set 'cache=TRUE' in the chunk options
## to make it run faster in subsequent knittings.

championships <- read_tsv("WCA_export_championships.tsv.bz2")
competitions <- read_tsv("WCA_export_Competitions.tsv.bz2")
continents <- read_tsv("WCA_export_Continents.tsv.bz2")
countries <- read_tsv("WCA_export_Countries.tsv.bz2")
eligible_country_iso2s_for_championship <- read_tsv("WCA_export_eligible_country_iso2s_for_championship.tsv.bz2")
events <- read_tsv("WCA_export_Events.tsv.bz2")
formats <- read_tsv("WCA_export_Formats.tsv.bz2")
persons <- read_tsv("WCA_export_Persons.tsv.bz2")
ranksaverage <- read_tsv("WCA_export_RanksAverage_333.tsv.bz2")
rankssingle <- read_tsv("WCA_export_RanksSingle_333.tsv.bz2")
results <- read_tsv("WCA_export_Results_333.tsv.bz2")
roundtypes <- read_tsv("WCA_export_RoundTypes.tsv.bz2")
scrambles <- read_tsv("WCA_export_Scrambles.tsv.bz2")
```


## Questions

### Active Speed Cubers

How many active (3x3x3) speedcubers are there registered with the WCA? For this question an *active speeedcuber* is defined as any person registered in the WCA who has competed in at least two competitions in the years 2022--2024. 


```{r}
## Create new dataset valid_competitions that will filter data for years 2022-2024 exclusively, then filter results for only valid competitions, filtering competition count greater than or less than 2

valid_competitions <- competitions |>
      filter(year >= 2022 & year <= 2024) |>
      select(id)

active_cubers <- results |>
      filter(competitionId %in% valid_competitions$id) |>
      group_by(personId) |>
      summarize(competition_count = n_distinct(competitionId)) |>
      filter(competition_count >= 2)
      nrow(active_cubers)
```

**There are a total of 39482 speedcubers who have competed in at least two competitions in the years 2022-2024.**

### World Records

This question has two parts:

1. Who holds the current world record single? 

```{r}
## joining results data to rankssingle data to collect names and arrange the names from best score to worst score and selecting the name of record holder with their rank and competitionId, returning the first row using slice function and returning the data using head function

world_record_holder <- rankssingle |>
      arrange(best) |>
      left_join(results, by = c('best', 'personId', 'eventId')) |>
      select(personName, worldRank, competitionId) |>
      slice(1)
      head(world_record_holder)

```

**Max Park holds the current world record single of a best score of 313.**


On what date was this record set?


```{r}
## filtering the id's of competitions dataset of the record holder's competitionId and selecting the year, month, and day of the row with the corresponding competitionId and returning the data using head function

world_record_date <- competitions |>
      filter(id == world_record_holder$competitionId) |>
      select(year, month, day)
      head(world_record_date)

```

**The record was set on 6/11/2023.**



2. Who *previously* held the world record single? On what date was this previous record set?

```{r}
## Arrange the best times then join necessary tables to have the date, name, and competitionId correspond to each other, then using filter function to condition the year, month, day, to find the time before the current world record date, then save the information of the previous record holder name, best time, competitionId, and time in the prev_world_record_holder dataset using select function and return it using the head function and slice to extract the first row of the dataset

prev_world_record_holder <- rankssingle |>
      arrange(best) |>
      left_join(results, by = c('best', 'personId', 'eventId')) |>
      left_join(competitions, by = c('competitionId' = 'id')) |>
      filter(year < world_record_date$year | 
               (year == world_record_date$year & month < world_record_date$month) | 
               (year == world_record_date$year & month == world_record_date$month & day < world_record_date$day)) |>
      select(personName, best, competitionId, year, month, day) |>
      slice(1)
      head(prev_world_record_holder)
```

**Yusheng Du previously held the world record single, set on 11/24/2018.**


### Regional Rankings

This question has two parts:

1. Amongst all speedcubers, who is the top ranked male speedcuber (for best single solve) in Australia?

```{r}
## Filter persons dataset to extract australian males, join filtered data with rankssingle dataset to get the rankings, arrange the best time using arrange function, take first row using slice function, then save the information of the best male speedcuber in Australia name, countryId, and best time in the top_male_australia dataset using select function, and return the dataset using the head function

top_male_australia <- persons |>
      filter(countryId == "Australia" & gender == "m") |>
      left_join(rankssingle, by = c("id" = "personId")) |>
      arrange(best) |>
      slice(1) |>
      select(name, countryId, best)
      head(top_male_australia)
```

**The top ranked male speedcuber for best single solve in Australia is Jode Brewster.**


2. Amongst all speedcubers, who is the top ranked female speedcuber (for best single solve time) in Europe?

```{r}
## Creating list of European countries by filtering for Euope categories in the countries dataset, then filtering the persons dataset for females that are from European countries and joining this filtered data with the rankssingle dataset, then arranging the best time using arrange function, take first row using slice function, then save the information of the best female speedcuber in Europe name, countryId, and best time in the top_female_europe dataset using select function, and return the dataset using the head function

european_countries <- countries |>
      filter(continentId == "_Europe") |>
      pull(name)

top_female_europe <- persons %>%
      filter(countryId %in% european_countries & gender == "f") |>
      left_join(rankssingle, by = c("id" = "personId")) |>
      arrange(best) |>
      slice(1) |>
      select(name, countryId, best)
      head(top_female_europe)
```

**The rop ranked female speedcuber for best single solve time in Europe is Magdalena Pabisz.**



### Time Until Sub-5

Having a time below 5 seconds is considered an elite achievement and most speedcubers have to complete a large number of solves before they can obtain a sub-5 second solve. 

**NOTE**: Each round of a competition has 5 solves that should be considered separately when counting the number of solves.


1. For the current top 10 speedcubers in the world (as recorded in the RanksSingle table), on average, how many solves did they have to do before achieving a sub-5 second solve?


```{r}
## Create top 10 speedcubers dataset from rankssingle dataset, slicing the first 10 rows and extracting it to the top_10_speedcubers dataset using select function, then create top_10_results dataset from top_10_speedcubers dataset, joining competitions and results dataset and organizing the data based on personName, year, month, day in chronological order from each distinct person, and create count column that will count until value1-value5 for each row has a value less than 500, but also accounting for -1 values as DNF values, then create average_count dataset from top_10_results to find the average total counts until sub-5 solve from each distinct personName using group_by each personName and summarize with calculating using the mean function

top_10_speedcubers <- rankssingle |>
      arrange(worldRank) |>
      slice_head(n = 10) |>
      select(personId, best, worldRank, continentRank, countryRank)

top_10_results <- top_10_speedcubers |>
      left_join(results, by = "personId") |>
      filter(!is.na(personName)) |>
      left_join(competitions %>% select(id, year, month, day), 
                by = c("competitionId" = "id")) |>
      select(competitionId, eventId, personName, personId, value1, value2, 
             value3, value4, value5, year, month, day) |>
      arrange(personName, year, month, day) |>
      group_by(personName) |>
      mutate(sub_500 = pmin(value1, value2, value3, value4, value5) < 500 & 
               pmin(value1, value2, value3, value4, value5) != -1, 
             row = row_number()) |>
      filter(row <= min(row[sub_500], max(row), na.rm = TRUE)) %>%
      mutate(count = row) |>
      select(-sub_500, -row)
      
average_count <- top_10_results |>
      group_by(personName) |>
      summarize(max_count = max(count)) |>
      summarize(average_count = mean(max_count))
      head(average_count)
```

**For the current top 10 speedcubers, the average number of solves done before achieving a sub-5 second solve is 102.9.**



2. For **one** of the top 10 speedcubers make a plot of their solve times vs. the date of the solve, with date on the x-axis and solve time on the y-axis. 


```{r}
## Creating asher_kim dataset from top_10_results dataset, filtering Asher Kim rows of data, and merging month and day columns together for readability in making scatterplot, and creating new columns for solve attempts and solve times to include separate data points to the y axis, then for the modified asher_kim dataset, create scatterplot using geom_point, labeled with labs function, where graph is facet_wrap based on year and adjusting x axis for easier reading of the month and days, where x axis are the merged dates and the y axis are the solve times by 1/100th of a second

asher_kim <- top_10_results |>
      filter(personName == "Asher Kim-Magierek") |>
      mutate(date = paste(month, day, sep = "/")) |>
      pivot_longer(cols = c(value1, value2, value3, value4, value5),
                   names_to = "solve_attempt", 
                   values_to = "solve_time")
asher_kim |>
      ggplot(aes(x = date, y = solve_time, color = solve_attempt)) +
      geom_point() +
      facet_wrap(vars(year), scales = "free_x") +
      labs(x = "Date (Month/Day)", y = "Solve Time (1/100th sec)", 
           title = "Asher Kim-Magierek's Solve Times") +
      theme_minimal() +
      theme(axis.text.x = element_text(angle = 45, hjust = 1))
```


**Asher's solve times in 2017 vary the most compared to the other years of solve times.**


### Up-and-Coming Speed Cubers

Which speed cubers **not** in the top 10,000 (worldwide for single best time) should we keep an eye on for the near future? 

The idea here is to identify "up-and-coming" speedcubers who are not yet achieving elite times. Come up with a list of **five** speedcubers (provide their names and WCA IDs) that you have identified as "up-and-coming". There is no one way to answer this question and the goal is to provide an analysis of the data that justifies the selection of your five names.

```{r}
## Add your code here


```

**Write your answer here.**



### Region Rivalries

Europe and North America are both regions with strong speedcubers in the WCA. 

Which region has the faster group of speedcubers on average? 

To answer this question, characterize each person using their best *average* score according to their listing in the `ranksaverage` table. In the `persons` table the `countryId` indicates each person's country affiliation. The `countries` table lists the region that each country is in via the `continentId` column (Europe is "_Europe" and North America is "_North America").

Before attempting to answer the question, state what you expect the answer to be below.

**We expect North America to have faster speedcubers on average than Europe.**



```{r}
## Join ranskaverage with the persons dataset and selected the columns personId, best, and countryId

regional_averages <- ranksaverage |>
      inner_join(persons, by = c("personId" = "id")) |>
      select(personId, best, countryId)

#Joined regional averages with countries dataset to get continent column

regional_averages <- regional_averages |>
      inner_join(countries, by = c("countryId" = "id"))

#Filtered for Europe and North America through filter function and calculated average scores for each region taking out the NA values from the scores

regional_averages_strong <- regional_averages |>
      filter(continentId %in% c("_Europe", "_North America")) |>
      group_by(continentId) |>
      summarize(avg_best_score = mean(best, na.rm = TRUE), 
                median_best_score = median(best, na.rm = TRUE), 
                num_cubers = n())
      head(regional_averages_strong)
```

What do you conclude about speedcubers in Europe vs. North America?

**North America has the faster group of speedcubers on average comapred to Europe. North America's average best score is slighlty lower than Europes.**


### Alternative Explanations

Develop an alternative explanation/hypothesis regarding speedcubers from Europe and North America that is 

1. Consistent with the results you produced in the previous question; but

2. Provides a different interpretation or explanation for what is going on. 

If the results from the previous question were unexpected, make use of systems thinking to develop an alternative hypothesis. If the results were consistent with your expectations, then use skeptical thinking. In either case, you should present an analysis that shows evidence for or against this alternative explanation relative to the conclusion that you made in the previous question.

**State your alternative explanation here.**

```{r}
## Add your code here

```

**Summarize the results of your alternative analysis here.**





## Discussion

